{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/icb/alioguz.can/miniconda3/envs/campa_pt/bin/python\n",
      "gpusrv34.scidom.de\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "print(sys.executable)\n",
    "import socket\n",
    "print(socket.gethostname())\n",
    "import os\n",
    "os.chdir(\"/home/icb/alioguz.can/projects/campa_pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "TF_ENABLE_ONEDNN_OPTS=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/icb/alioguz.can/miniconda3/envs/campa_pt/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-01-15 20:32:30.261846: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-15 20:32:31.601583: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2025-01-15 20:32:31.601707: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2025-01-15 20:32:31.601720: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/icb/alioguz.can/miniconda3/envs/campa_pt/lib/python3.9/site-packages/numba/core/decorators.py:246: RuntimeWarning: nopython is set for njit and is ignored\n",
      "  warnings.warn('nopython is set for njit and is ignored', RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading config from /ictstr01/home/icb/alioguz.can/projects/campa_pt/notebooks/params/campa.ini\n",
      "CAMPAConfig (fname: /ictstr01/home/icb/alioguz.can/projects/campa_pt/notebooks/params/campa.ini)\n",
      "EXPERIMENT_DIR: /home/icb/alioguz.can/projects/campa_pt/notebooks/example_experiments\n",
      "BASE_DATA_DIR: /home/icb/alioguz.can/projects/campa_pt/notebooks/example_data\n",
      "CO_OCC_CHUNK_SIZE: 10000000.0\n",
      "data_config/exampledata: /home/icb/alioguz.can/projects/campa_pt/notebooks/params/ExampleData_constants.py\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from campa.tl import (\n",
    "    Cluster,\n",
    "    Estimator,\n",
    "    TorchEstimator,\n",
    "    Predictor,\n",
    "    TorchPredictor,\n",
    "    Experiment,\n",
    "    TorchExperiment,\n",
    "    ModelComparator,\n",
    "    run_experiments,\n",
    "    run_torch_experiments\n",
    ")\n",
    "from campa.data import MPPData\n",
    "from campa.utils import init_logging\n",
    "from campa.constants import campa_config\n",
    "# init logging with level INFO=20, WARNING=30\n",
    "init_logging(level=30)\n",
    "# read correct campa_config -- created with setup.ipynb\n",
    "CAMPA_DIR = Path.cwd()\n",
    "campa_config.config_fname = CAMPA_DIR / \"notebooks/params/campa.ini\"\n",
    "print(campa_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import backend as K\n",
    "# import torch\n",
    "# torch.cuda.empty_cache()\n",
    "# # Clear the current session\n",
    "# K.clear_session()\n",
    "\n",
    "# # Optionally, reset the default graph\n",
    "# tf.compat.v1.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get Experiments from config\n",
    "exps = Experiment.get_experiments_from_config(\"notebooks/params/example_experiment_params.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_experiments(exps, mode=\"trainval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment name: MPPleiden\n",
      "Experiment is stored in: /home/icb/alioguz.can/projects/campa_pt/notebooks/example_experiments/test/MPPleiden\n"
     ]
    }
   ],
   "source": [
    "exp = exps[2]\n",
    "print(\"Experiment name:\", exp.name)\n",
    "print(\"Experiment is stored in:\", exp.full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m est \u001b[38;5;241m=\u001b[39m \u001b[43mEstimator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexps\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/ictstr01/home/icb/alioguz.can/projects/campa_pt/campa/tl/_estimator.py:93\u001b[0m, in \u001b[0;36mEstimator.__init__\u001b[0;34m(self, exp)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexp \u001b[38;5;241m=\u001b[39m exp\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m exp\u001b[38;5;241m.\u001b[39mestimator_config\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m---> 93\u001b[0m     key: LossEnum(val)\u001b[38;5;241m.\u001b[39mget_fn() \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mloss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m     94\u001b[0m }\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetrics\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     96\u001b[0m     key: LossEnum(val)\u001b[38;5;241m.\u001b[39mget_fn() \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetrics\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m     97\u001b[0m }\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mobject\u001b[39m] \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "est = Estimator(exps[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"VAEModel\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_12 (InputLayer)          [(None, 3, 3, 34)]   0           []                               \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 3, 3, 32)     1120        ['input_12[0][0]']               \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)            (None, 288)          0           ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 32)           9248        ['flatten_4[0][0]']              \n",
      "                                                                                                  \n",
      " encoder (Functional)           (None, 16)           11440       ['input_12[0][0]']               \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 16)           528         ['dense_14[0][0]']               \n",
      "                                                                                                  \n",
      " decoder (Functional)           (None, 34)           578         ['encoder[0][0]']                \n",
      "                                                                                                  \n",
      " latent (Dense)                 (None, 32)           544         ['dense_15[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 12,018\n",
      "Trainable params: 12,018\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_12 (InputLayer)          [(None, 3, 3, 34)]   0           []                               \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 3, 3, 32)     1120        ['input_12[0][0]']               \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)            (None, 288)          0           ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 32)           9248        ['flatten_4[0][0]']              \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 16)           528         ['dense_14[0][0]']               \n",
      "                                                                                                  \n",
      " latent (Dense)                 (None, 32)           544         ['dense_15[0][0]']               \n",
      "                                                                                                  \n",
      " tf.split_4 (TFOpLambda)        [(None, 16),         0           ['latent[0][0]']                 \n",
      "                                 (None, 16)]                                                      \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_4 (TFOpLamb  (2,)                0           ['tf.split_4[0][0]']             \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.multiply_8 (TFOpLambda  (None, 16)          0           ['tf.split_4[0][1]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.random.normal_4 (TFOpLambda  (None, 16)          0           ['tf.compat.v1.shape_4[0][0]']   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.exp_4 (TFOpLambda)     (None, 16)           0           ['tf.math.multiply_8[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.multiply_9 (TFOpLambda  (None, 16)          0           ['tf.random.normal_4[0][0]',     \n",
      " )                                                                'tf.math.exp_4[0][0]']          \n",
      "                                                                                                  \n",
      " tf.__operators__.add_4 (TFOpLa  (None, 16)          0           ['tf.math.multiply_9[0][0]',     \n",
      " mbda)                                                            'tf.split_4[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 11,440\n",
      "Trainable params: 11,440\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_13 (InputLayer)       [(None, 16)]              0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 34)                578       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 578\n",
      "Trainable params: 578\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(Estimator(exps[0]).model.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 10s 346ms/step - loss: 5223.8276 - decoder_loss: 5223.8062 - latent_loss: 0.0221 - decoder_mean_squared_error: 0.7407 - latent_kl_loss: 0.0223 - val_loss: 5243.8989 - val_decoder_loss: 5243.8716 - val_latent_loss: 0.0274 - val_decoder_mean_squared_error: 0.7189 - val_latent_kl_loss: 0.0274\n"
     ]
    }
   ],
   "source": [
    "_ = est.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 419ms/step\n",
      "1/1 [==============================] - 0s 392ms/step\n",
      "319/319 [==============================] - 1s 2ms/step\n",
      "319/319 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_torch = Predictor(exps[1])\n",
    "pred_torch.evaluate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"VAEModel\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 14)]         0           []                               \n",
      "                                                                                                  \n",
      " condition_encoder (Functional)  (None, 10)          260         ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)           [(None, 3, 3, 34)]   0           []                               \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 3, 3, 10)     0           ['condition_encoder[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 3, 3, 44)     0           ['input_1[0][0]',                \n",
      "                                                                  'lambda[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 3, 3, 32)     1440        ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 288)          0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 32)           9248        ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " encoder (Functional)           (None, 16)           12020       ['input_1[0][0]',                \n",
      "                                                                  'input_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 16)           528         ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " decoder (Functional)           (None, 34)           1178        ['encoder[0][0]',                \n",
      "                                                                  'input_3[0][0]']                \n",
      "                                                                                                  \n",
      " latent (Dense)                 (None, 32)           544         ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 12,938\n",
      "Trainable params: 12,938\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(est.model.model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment name: MPPleiden\n",
      "Experiment is stored in: /home/icb/alioguz.can/projects/campa_pt/notebooks/example_experiments/test/CondVAE_pert-CC\n"
     ]
    }
   ],
   "source": [
    "torch_exps = TorchExperiment.get_experiments_from_config(\"notebooks/params/example_experiment_params_torch.py\")\n",
    "print(\"Experiment name:\", torch_exps[2].name)\n",
    "print(\"Experiment is stored in:\", torch_exps[1].full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:TorchEstimator:WARNING: weights_path set to true but no trained model found in /home/icb/alioguz.can/projects/campa_pt/notebooks/example_experiments/test/VAE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAEModelTorch(\n",
      "  (encoder): Sequential(\n",
      "    (0): Conv2d(34, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Flatten(start_dim=1, end_dim=-1)\n",
      "    (3): Linear(in_features=288, out_features=32, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (6): ReLU()\n",
      "  )\n",
      "  (latent): Linear(in_features=16, out_features=32, bias=True)\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=16, out_features=34, bias=True)\n",
      "  )\n",
      ")\n",
      "12018\n"
     ]
    }
   ],
   "source": [
    "est_torch = TorchEstimator(torch_exps[0])\n",
    "print(est_torch.model)\n",
    "est_torch.model.total_trainable_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 1/1 [00:00<00:00, 35.97it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'epoch': 0,\n",
       " 'loss': 4481.19189453125,\n",
       " 'val_loss': 4582.275390625,\n",
       " 'decoder_loss': 4481.179870605469,\n",
       " 'latent_loss': 0.01203770306892693}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_torch.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:TorchEstimator:WARNING: weights_path set to true but no trained model found in /home/icb/alioguz.can/projects/campa_pt/notebooks/example_experiments/test/VAE\n"
     ]
    }
   ],
   "source": [
    "pred_torch = TorchPredictor(torch_exps[0])\n",
    "pred_torch.evaluate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results folder /home/icb/alioguz.can/projects/campa_pt/notebooks/example_experiments/test/VAE/results_epoch000\n",
      "['val', 'val_imgs']\n"
     ]
    }
   ],
   "source": [
    "results_folder = os.path.join(pred_torch.exp.full_path, f\"results_epoch{pred_torch.est.epoch:03d}\")\n",
    "print(\"Results folder\", results_folder)\n",
    "print(os.listdir(results_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPPData for ExampleData (123 mpps with shape (3, 3, 34) from 8 objects). Data keys: ['obj_ids', 'y', 'x', 'mpp', 'labels', 'conditions', 'latent'].\n"
     ]
    }
   ],
   "source": [
    "print(MPPData.from_data_dir(os.path.join(results_folder, \"val\"), data_config=\"ExampleData\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot read with memmap:  /home/icb/alioguz.can/projects/campa_pt/notebooks/example_experiments/test/VAE/results_epoch001/val/clustering.npy\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cl \u001b[38;5;241m=\u001b[39m \u001b[43mCluster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_exp_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch_exps\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/ictstr01/home/icb/alioguz.can/projects/campa_pt/campa/tl/_cluster.py:281\u001b[0m, in \u001b[0;36mCluster.from_exp_split\u001b[0;34m(cls, exp)\u001b[0m\n\u001b[1;32m    273\u001b[0m cluster_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubsample\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    274\u001b[0m cluster_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster_data_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m    275\u001b[0m     exp\u001b[38;5;241m.\u001b[39mdir,\n\u001b[1;32m    276\u001b[0m     exp\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults_epoch\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexp\u001b[38;5;241m.\u001b[39mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m03d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    278\u001b[0m     exp\u001b[38;5;241m.\u001b[39mevaluate_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    279\u001b[0m )\n\u001b[0;32m--> 281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcluster_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/ictstr01/home/icb/alioguz.can/projects/campa_pt/campa/tl/_cluster.py:192\u001b[0m, in \u001b[0;36mCluster.__init__\u001b[0;34m(self, config, cluster_mpp, save_config)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cluster_mpp \u001b[38;5;241m=\u001b[39m cluster_mpp\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# try to load it from disk if not already initialised\u001b[39;00m\n\u001b[0;32m--> 192\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcluster_mpp\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# initialise annotation\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cluster_annotation: pd\u001b[38;5;241m.\u001b[39mDataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/ictstr01/home/icb/alioguz.can/projects/campa_pt/campa/tl/_cluster.py:301\u001b[0m, in \u001b[0;36mCluster.cluster_mpp\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;124;03m:class:`MPPData` that is used for clustering.\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \n\u001b[1;32m    298\u001b[0m \u001b[38;5;124;03mNone if data could not be loaded.\u001b[39;00m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cluster_mpp \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 301\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cluster_mpp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_cluster_mpp\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cluster_mpp\n",
      "File \u001b[0;32m/ictstr01/home/icb/alioguz.can/projects/campa_pt/campa/tl/_cluster.py:323\u001b[0m, in \u001b[0;36mCluster._load_cluster_mpp\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;66;03m# load data\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 323\u001b[0m     mpp_data \u001b[38;5;241m=\u001b[39m \u001b[43mMPPData\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_data_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcampa_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEXPERIMENT_DIR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptional_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmpp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mumap\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_config_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded cluster_mpp \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmpp_data\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mpp_data\n",
      "File \u001b[0;32m/ictstr01/home/icb/alioguz.can/projects/campa_pt/campa/data/_data.py:192\u001b[0m, in \u001b[0;36mMPPData.from_data_dir\u001b[0;34m(cls, data_dir, data_config, mode, base_dir, keys, optional_keys, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m# print(f\"!!!!!adding from {base_dir}, {data_dir}\")\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# second, add mpp_data\u001b[39;00m\n\u001b[1;32m    191\u001b[0m res_keys, res_optional_keys \u001b[38;5;241m=\u001b[39m _get_keys(keys, optional_keys, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 192\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_data_from_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mres_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptional_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mres_optional_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmpp_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msubset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded data from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, with base data from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmpp_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbase_data_dir\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_dir \u001b[38;5;241m=\u001b[39m data_dir\n",
      "File \u001b[0;32m/ictstr01/home/icb/alioguz.can/projects/campa_pt/campa/data/_data.py:508\u001b[0m, in \u001b[0;36mMPPData.add_data_from_dir\u001b[0;34m(self, data_dir, keys, optional_keys, subset, **kwargs)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[38;5;66;03m# check that obj_ids from mpp_to_add are the same / a subset of the current obj_ids\u001b[39;00m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m subset:\n\u001b[0;32m--> 508\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munique_obj_ids)\u001b[38;5;241m.\u001b[39missuperset(mpp_to_add\u001b[38;5;241m.\u001b[39munique_obj_ids)\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;66;03m# subset self to the obj_ids in mpp_to_add\u001b[39;00m\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubset(obj_ids\u001b[38;5;241m=\u001b[39mmpp_to_add\u001b[38;5;241m.\u001b[39munique_obj_ids)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cl = Cluster.from_exp_split(torch_exps[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ictstr01/home/icb/alioguz.can/projects/campa_pt/campa/tl/_cluster.py:598: FutureWarning: In the future, the default backend for leiden will be igraph instead of leidenalg.\n",
      "\n",
      " To achieve the future defaults please pass: flavor=\"igraph\" and n_iterations=2.  directed must also be False to work with igraph's implementation.\n",
      "  sc.tl.leiden(\n",
      "WARNING:MPPData:Saving partial keys of mpp data without a base_data_dir to enable correct loading\n"
     ]
    }
   ],
   "source": [
    "print(cl.config[\"leiden_resolution\"])\n",
    "cl.create_clustering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment for ['VAE', 'CondVAE_pert-CC', 'MPPleiden'] with mode trainval\n",
      "Training model for VAE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 100%|██████████| 1/1 [00:00<00:00,  2.00it/s]\n",
      "WARNING:TorchEstimator:WARNING: weights_path set to true but no trained model found in /home/icb/alioguz.can/projects/campa_pt/notebooks/example_experiments/test/VAE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model for VAE\n",
      "Clustering results for VAE\n",
      "Cannot read with memmap:  /home/icb/alioguz.can/projects/campa_pt/notebooks/example_experiments/test/VAE/results_epoch001/val/clustering.npy\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun_torch_experiments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch_exps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrainval\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/ictstr01/home/icb/alioguz.can/projects/campa_pt/campa/tl/_experiment.py:746\u001b[0m, in \u001b[0;36mrun_torch_experiments\u001b[0;34m(exps, mode)\u001b[0m\n\u001b[1;32m    744\u001b[0m \u001b[38;5;66;03m# cluster model\u001b[39;00m\n\u001b[1;32m    745\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClustering results for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexp_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 746\u001b[0m cl \u001b[38;5;241m=\u001b[39m \u001b[43mCluster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_exp_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    747\u001b[0m cl\u001b[38;5;241m.\u001b[39mcreate_clustering()\n\u001b[1;32m    748\u001b[0m \u001b[38;5;66;03m# predict cluster for images\u001b[39;00m\n",
      "File \u001b[0;32m/ictstr01/home/icb/alioguz.can/projects/campa_pt/campa/tl/_cluster.py:281\u001b[0m, in \u001b[0;36mCluster.from_exp_split\u001b[0;34m(cls, exp)\u001b[0m\n\u001b[1;32m    273\u001b[0m cluster_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubsample\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    274\u001b[0m cluster_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster_data_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m    275\u001b[0m     exp\u001b[38;5;241m.\u001b[39mdir,\n\u001b[1;32m    276\u001b[0m     exp\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults_epoch\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexp\u001b[38;5;241m.\u001b[39mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m03d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    278\u001b[0m     exp\u001b[38;5;241m.\u001b[39mevaluate_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    279\u001b[0m )\n\u001b[0;32m--> 281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcluster_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/ictstr01/home/icb/alioguz.can/projects/campa_pt/campa/tl/_cluster.py:192\u001b[0m, in \u001b[0;36mCluster.__init__\u001b[0;34m(self, config, cluster_mpp, save_config)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cluster_mpp \u001b[38;5;241m=\u001b[39m cluster_mpp\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# try to load it from disk if not already initialised\u001b[39;00m\n\u001b[0;32m--> 192\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcluster_mpp\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# initialise annotation\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cluster_annotation: pd\u001b[38;5;241m.\u001b[39mDataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/ictstr01/home/icb/alioguz.can/projects/campa_pt/campa/tl/_cluster.py:301\u001b[0m, in \u001b[0;36mCluster.cluster_mpp\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;124;03m:class:`MPPData` that is used for clustering.\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \n\u001b[1;32m    298\u001b[0m \u001b[38;5;124;03mNone if data could not be loaded.\u001b[39;00m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cluster_mpp \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 301\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cluster_mpp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_cluster_mpp\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cluster_mpp\n",
      "File \u001b[0;32m/ictstr01/home/icb/alioguz.can/projects/campa_pt/campa/tl/_cluster.py:323\u001b[0m, in \u001b[0;36mCluster._load_cluster_mpp\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;66;03m# load data\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 323\u001b[0m     mpp_data \u001b[38;5;241m=\u001b[39m \u001b[43mMPPData\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_data_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcampa_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEXPERIMENT_DIR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptional_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmpp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mumap\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_config_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded cluster_mpp \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmpp_data\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mpp_data\n",
      "File \u001b[0;32m/ictstr01/home/icb/alioguz.can/projects/campa_pt/campa/data/_data.py:192\u001b[0m, in \u001b[0;36mMPPData.from_data_dir\u001b[0;34m(cls, data_dir, data_config, mode, base_dir, keys, optional_keys, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m# print(f\"!!!!!adding from {base_dir}, {data_dir}\")\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# second, add mpp_data\u001b[39;00m\n\u001b[1;32m    191\u001b[0m res_keys, res_optional_keys \u001b[38;5;241m=\u001b[39m _get_keys(keys, optional_keys, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 192\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_data_from_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mres_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptional_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mres_optional_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmpp_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msubset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded data from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, with base data from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmpp_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbase_data_dir\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_dir \u001b[38;5;241m=\u001b[39m data_dir\n",
      "File \u001b[0;32m/ictstr01/home/icb/alioguz.can/projects/campa_pt/campa/data/_data.py:508\u001b[0m, in \u001b[0;36mMPPData.add_data_from_dir\u001b[0;34m(self, data_dir, keys, optional_keys, subset, **kwargs)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[38;5;66;03m# check that obj_ids from mpp_to_add are the same / a subset of the current obj_ids\u001b[39;00m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m subset:\n\u001b[0;32m--> 508\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munique_obj_ids)\u001b[38;5;241m.\u001b[39missuperset(mpp_to_add\u001b[38;5;241m.\u001b[39munique_obj_ids)\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;66;03m# subset self to the obj_ids in mpp_to_add\u001b[39;00m\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubset(obj_ids\u001b[38;5;241m=\u001b[39mmpp_to_add\u001b[38;5;241m.\u001b[39munique_obj_ids)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_torch_experiments(torch_exps, mode=\"trainval\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
